# -*- coding: utf-8 -*-
"""Mechanism Design.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15UBG39r2E9jILabkvUh97hDNdmhOkC_t
"""

import numpy as np
from math import exp

class Agent:
    def __init__(self, level=1):
        self.level = level
        self.points = 0
        self.actions = []

class CentralAgent(Agent):
    def __init__(self, lambda1, lambda2, lambda3):
        super().__init__()
        self.lambda1 = lambda1
        self.lambda2 = lambda2
        self.lambda3 = lambda3

    def compute_payoff(self, N5, N4, N1):
        return self.lambda1 * N5 + self.lambda2 * N4 - self.lambda3 * N1

    def adjust_padjust(self, N5, current_padjust):
        return current_padjust + 0.1 if N5 == 0 else current_padjust

class IntermediaryAgent(Agent):
    def __init__(self, alpha, lambda_decay):
        super().__init__()
        self.alpha = alpha
        self.lambda_decay = lambda_decay
        self.padjust = 0
        self.prob_passive_list = []

    def choose_strategy(self, target):
        compliance = self.calculate_compliance(target)
        expected_payoff_passive = 3 * compliance + self.padjust - 1
        expected_payoff_intervene = compliance

        # Store the probability of choosing PASSIVE
        prob_passive = expected_payoff_passive / (expected_payoff_passive + expected_payoff_intervene)
        self.prob_passive_list.append(prob_passive)

        print(f"Intermediary: Padjust = {self.padjust}, Expected payoff for PASSIVE = {expected_payoff_passive}, INTERVENE = {expected_payoff_intervene}")
        return "PASSIVE" if expected_payoff_passive > expected_payoff_intervene else "INTERVENE"


    def calculate_compliance(self, target):
        weighted_sum = sum(self.lambda_decay ** (len(target.actions) - i) * (1 if action == "COMPLY" else 0)
                           for i, action in enumerate(target.actions))
        return 1 / (1 + exp(-weighted_sum))

    def adjust_payoff(self, predicted_compliance, current_compliance):
        return self.alpha * (predicted_compliance - current_compliance)

class TargetAgent(Agent):
    def __init__(self, level_payoffs, level_thresholds, beta, gamma):
        super().__init__()
        self.level_payoffs = level_payoffs
        self.level_thresholds = level_thresholds
        self.beta = beta
        self.gamma = gamma
        self.compliance_probabilities = []


    def choose_strategy(self, intermediary_strategy):
        expected_payoff_comply = self.level_payoffs[min(self.level, len(self.level_payoffs) - 1)] + (2 if intermediary_strategy == "PASSIVE" else 1) + self.reward_function()
        expected_payoff_defy = (0 if intermediary_strategy == "PASSIVE" else -1)

        print(f"Target: Expected payoff for COMPLY = {expected_payoff_comply}, DEFY = {expected_payoff_defy}")

        # Mostly deterministic, but with 15% randomness
        if expected_payoff_comply > expected_payoff_defy:
            primary_choice = "COMPLY"
            secondary_choice = "DEFY"
        else:
            primary_choice = "DEFY"
            secondary_choice = "COMPLY"
        prob_comply = np.exp(expected_payoff_comply)/ np.exp(expected_payoff_comply + expected_payoff_defy)



        self.strategy = primary_choice if np.random.rand() > 0.15 else secondary_choice
        self.compliance_probabilities.append(prob_comply)

        self.actions.append(self.strategy)
        self.points += (2 if self.strategy == "COMPLY" else -1)
        if intermediary_strategy == "INTERVENE" and self.strategy == "COMPLY":
            self.points += 1
        if self.points >= self.level_thresholds[min(self.level, len(self.level_thresholds) - 1)]:
            self.level = min(5, self.level + 1)
            self.points = 0


    def reward_function(self):
        if not self.actions:
            return 0
        predicted_compliance = current_compliance = self.actions.count("COMPLY") / len(self.actions)
        sigmoid_weight = 1 / (1 + exp(self.gamma * (predicted_compliance - current_compliance)))
        return self.beta * sigmoid_weight

import numpy as np
from math import exp
import matplotlib.pyplot as plt

def plot_changes(target_levels, compliance_probabilities, intermediary_prob_passive):

    # Plotting change in target levels
    plt.figure(figsize=(10, 5))
    for i, levels in enumerate(target_levels):
        plt.plot(levels, label=f"Target {i+1}", alpha=0.5)
    plt.xlabel("Iteration")
    plt.ylabel("Level")
    plt.title("Change in Target Level Over Iterations")
    plt.legend()
    plt.grid(True)
    plt.show()

    # Plotting change in compliance probability
    plt.figure(figsize=(10, 5))
    for i, probabilities in enumerate(compliance_probabilities):
        plt.plot(probabilities, label=f"Target {i+1}", alpha=0.5)
    plt.xlabel("Iteration")
    plt.ylabel("Compliance Probability")
    plt.title("Change in Compliance Probability Over Iterations")
    plt.legend()
    plt.grid(True)
    plt.show()

    # Plotting change in probability of intermediary choosing PASSIVE
    plt.figure(figsize=(10, 5))
    for i, probabilities in enumerate(intermediary_prob_passive):
        plt.plot(probabilities, label=f"Intermediary {i+1}", alpha=0.5)
    plt.xlabel("Iteration")
    plt.ylabel("Probability of PASSIVE")
    plt.title("Change in Probability of Intermediary Choosing PASSIVE Over Iterations")
    plt.legend()
    plt.grid(True)
    plt.show()

def simulate_game(steps):
    central_agent = CentralAgent(lambda1=1, lambda2=0.5, lambda3=0.1)
    intermediary_agents = [IntermediaryAgent(alpha=0.01, lambda_decay=0.9) for _ in range(5)]
    target_agents = [TargetAgent(level_payoffs=[0, 1, 2, 3, 4], level_thresholds=[5, 10, 15, 20, 25], beta=0.5, gamma=0.1) for _ in range(5)]

    target_levels = [[] for _ in target_agents]
    compliance_probabilities = [[] for _ in target_agents]
    intermediary_prob_passive = [[] for _ in intermediary_agents]

    for step in range(steps):
        N1, N4, N5 = 0, 0, 0
        print(f"\nStep {step+1}:")
        for i, (target, intermediary_agent) in enumerate(zip(target_agents, intermediary_agents)):
            intermediary_strategy = intermediary_agent.choose_strategy(target)
            target.choose_strategy(intermediary_strategy)
            print(f"Target {i+1} is at level {target.level}, chose to {target.strategy}, Intermediary chose {intermediary_strategy}. Target points = {target.points}, Threshold for level {target.level} = {target.level_thresholds[min(target.level, len(target.level_thresholds) - 1)]}")

            if target.level == 1: N1 += 1
            elif target.level == 4: N4 += 1
            elif target.level == 5: N5 += 1

            target_levels[i].append(target.level)
            compliance_probabilities[i].append(intermediary_agent.calculate_compliance(target))
            intermediary_prob_passive[i].append(intermediary_agent.prob_passive_list[-1])

        central_payoff = central_agent.compute_payoff(N5, N4, N1)
        print(f"Central agent payoff = {central_payoff}")
        for intermediary_agent in intermediary_agents:
            intermediary_agent.padjust = central_agent.adjust_padjust(N5, intermediary_agent.padjust)

    plot_changes(target_levels, compliance_probabilities, intermediary_prob_passive)
    last_iteration = steps - 1
    avg_prob_comply = sum([float(target.compliance_probabilities[last_iteration]) for target in target_agents]) / len(target_agents)
    avg_prob_passive = sum([float(intermediary.prob_passive_list[last_iteration]) for intermediary in intermediary_agents]) / len(intermediary_agents)

    print(f"\nAt the last iteration:")
    print(f"Average probability of Target choosing COMPLY: {avg_prob_comply:.2f}")
    print(f"Average probability of Intermediary choosing PASSIVE: {avg_prob_passive:.2f}")

simulate_game(steps=200)