# -*- coding: utf-8 -*-
"""mechanism_design

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g2oR9h0vQL2yimh54fDZ0t_m1adynG6T
"""

import numpy as np
from math import exp

class Agent:
    def __init__(self, level=1):
        self.level = level
        self.points = 0
        self.actions = []

class CentralAgent(Agent):
    def __init__(self, lambda1, lambda2, lambda3):
        super().__init__()
        self.lambda1 = lambda1
        self.lambda2 = lambda2
        self.lambda3 = lambda3

    def compute_payoff(self, N5, N4, N1):
        return self.lambda1 * N5 + self.lambda2 * N4 - self.lambda3 * N1

    def adjust_padjust(self, N5, current_padjust):
        return current_padjust + 0.1 if N5 == 0 else current_padjust

class IntermediaryAgent(Agent):
    def __init__(self, alpha, lambda_decay):
        super().__init__()
        self.alpha = alpha
        self.lambda_decay = lambda_decay
        self.padjust = 0
        self.prob_passive_list = []
        self.previous_expected_compliance = 0
        self.choices = []

    def choose_strategy(self, target):
        compliance = self.calculate_compliance(target)
        expected_payoff_passive = 3 * compliance + self.padjust - 1
        expected_payoff_intervene = compliance

        # Store the probability of choosing PASSIVE
        prob_passive = expected_payoff_passive / (expected_payoff_passive + expected_payoff_intervene)
        self.prob_passive_list.append(prob_passive)

        print(f"Intermediary: Padjust = {self.padjust}, Expected payoff for PASSIVE = {expected_payoff_passive}, INTERVENE = {expected_payoff_intervene}")
        self.update_padjust()
        chosen_strategy = "PASSIVE" if expected_payoff_passive > expected_payoff_intervene else "INTERVENE"
        self.choices.append(chosen_strategy)
        return chosen_strategy

    def calculate_expected_compliance(self):
        expected_compliance = 0
        for n in range(1, len(self.prob_passive_list) + 1):
            product = np.prod(self.prob_passive_list[:n])
            expected_compliance += product
        return expected_compliance

    def calculate_compliance(self, target):
        weighted_sum = sum(self.lambda_decay ** (len(target.actions) - i) * (1 if action == "COMPLY" else 0)
                           for i, action in enumerate(target.actions))
        return 1 / (1 + exp(-weighted_sum))

    def adjust_payoff(self, predicted_compliance, current_compliance):
        return self.alpha * (predicted_compliance - current_compliance)

    def update_padjust(self):
        if not self.prob_passive_list:
            return  # No updates if the list is empty

        if hasattr(self, 'previous_expected_compliance'):
            current_expected_compliance = self.calculate_expected_compliance()
            self.padjust += self.alpha * (current_expected_compliance - self.previous_expected_compliance)
        else:
            self.previous_expected_compliance = self.calculate_expected_compliance()

class TargetAgent(Agent):
    def __init__(self, level_payoffs, level_thresholds, beta, gamma):
        super().__init__()
        self.level_payoffs = level_payoffs
        self.level_thresholds = level_thresholds
        self.beta = beta
        self.gamma = gamma
        self.compliance_probabilities = []
        self.previous_compliance_rate = 0


    def choose_strategy(self, intermediary_strategy, delta_compliance):
        expected_payoff_comply = self.level_payoffs[min(self.level, len(self.level_payoffs) - 1)] + (2 if intermediary_strategy == "PASSIVE" else 1) + self.reward_function(delta_compliance)
        expected_payoff_defy = (2 if intermediary_strategy == "PASSIVE" else 0)
        print(f"Target: Expected payoff for COMPLY = {expected_payoff_comply}, DEFY = {expected_payoff_defy}")

        # Mostly deterministic, but with 15% randomness
        if expected_payoff_comply > expected_payoff_defy:
            primary_choice = "COMPLY"
            secondary_choice = "DEFY"
        else:
            primary_choice = "DEFY"
            secondary_choice = "COMPLY"
        prob_comply = np.exp(expected_payoff_comply)/ np.exp(expected_payoff_comply + expected_payoff_defy)



        self.strategy = primary_choice if np.random.rand() > 0.20 else secondary_choice
        self.compliance_probabilities.append(prob_comply)

        self.actions.append(self.strategy)
        self.points += (2 if self.strategy == "COMPLY" else -1)
        if intermediary_strategy == "INTERVENE" and self.strategy == "COMPLY":
            self.points += 1
        if self.points >= self.level_thresholds[min(self.level, len(self.level_thresholds) - 1)]:
            self.level = min(5, self.level + 1)
            self.points = 0


    def reward_function(self, delta_expected_compliance):
        sigmoid_weight = 1 / (1 + exp(self.gamma * delta_expected_compliance))
        return self.beta * sigmoid_weight

    def calculate_delta_compliance(self):
        current_compliance_rate = self.actions.count("COMPLY") / len(self.actions) if self.actions else 0
        delta = current_compliance_rate - self.previous_compliance_rate
        self.previous_compliance_rate = current_compliance_rate  # Update for next calculation
        return delta

import numpy as np
from math import exp
import matplotlib.pyplot as plt

def plot_changes(target_levels, compliance_probabilities, intermediary_prob_passive):

    # Plotting change in target levels
    plt.figure(figsize=(10, 5))
    for i, levels in enumerate(target_levels):
        plt.plot(levels, label=f"Target {i+1}", alpha=0.5)
    plt.xlabel("Iteration")
    plt.ylabel("Level")
    plt.title("Change in Target Level Over Iterations")
    plt.legend()
    plt.grid(True)
    plt.show()


def plot_intermediary_decisions(intermediary_agents, steps):
    plt.figure(figsize=(10, 5))

    for i, agent in enumerate(intermediary_agents):
        passive_proportions = [agent.choices[:step].count("PASSIVE") / step if step != 0 else 0 for step in range(1, steps + 1)]
        plt.plot(passive_proportions, label=f"Intermediary {i+1}", alpha=0.5)

    plt.xlabel("Iteration")
    plt.ylabel("Proportion of PASSIVE Choices")
    plt.title("PASSIVE Choices by Intermediary Agents Over Iterations")
    plt.legend()
    plt.grid(True)
    plt.show()

def plot_actions(target_agents, steps):
    plt.figure(figsize=(10, 5))

    for i, agent in enumerate(target_agents):
        # Calculate the proportion of "COMPLY" actions at each step
        comply_proportions = [agent.actions[:step].count("COMPLY") / step if step != 0 else 0 for step in range(1, steps + 1)]
        plt.plot(comply_proportions, label=f"Target {i+1}", alpha=0.5)

    plt.xlabel("Iteration")
    plt.ylabel("Proportion of COMPLY Actions")
    plt.title("COMPLY Actions Over Iterations for Each Target Agent")
    plt.legend()
    plt.grid(True)
    plt.show()

def simulate_game(steps):
    central_agent = CentralAgent(lambda1=1, lambda2=0.5, lambda3=0.1)
    intermediary_agents = [IntermediaryAgent(alpha=0.01, lambda_decay=0.9) for _ in range(5)]
    target_agents = [TargetAgent(level_payoffs=[0, 1, 2, 3, 4], level_thresholds=[5, 10, 15, 20, 25], beta=0.5, gamma=0.1) for _ in range(5)]

    target_levels = [[] for _ in target_agents]
    compliance_probabilities = [[] for _ in target_agents]
    intermediary_prob_passive = [[] for _ in intermediary_agents]

    for step in range(steps):
        N1, N4, N5 = 0, 0, 0
        print(f"\nStep {step+1}:")
        for i, (target, intermediary_agent) in enumerate(zip(target_agents, intermediary_agents)):
            delta_compliance = target.calculate_delta_compliance()
            intermediary_strategy = intermediary_agent.choose_strategy(target)
            target.choose_strategy(intermediary_strategy, delta_compliance)
            print(f"Target {i+1} is at level {target.level}, chose to {target.strategy}, Intermediary chose {intermediary_strategy}. Target points = {target.points}, Threshold for level {target.level} = {target.level_thresholds[min(target.level, len(target.level_thresholds) - 1)]}")

            if target.level == 1: N1 += 1
            elif target.level == 4: N4 += 1
            elif target.level == 5: N5 += 1

            target_levels[i].append(target.level)
            compliance_probabilities[i].append(intermediary_agent.calculate_compliance(target))
            intermediary_prob_passive[i].append(intermediary_agent.prob_passive_list[-1])

        central_payoff = central_agent.compute_payoff(N5, N4, N1)
        print(f"Central agent payoff = {central_payoff}")
        for intermediary_agent in intermediary_agents:
            intermediary_agent.padjust = central_agent.adjust_padjust(N5, intermediary_agent.padjust)

    plot_actions(target_agents, steps)
    plot_changes(target_levels, compliance_probabilities, intermediary_prob_passive)
    plot_intermediary_decisions(intermediary_agents, steps=100)


simulate_game(steps=100)
